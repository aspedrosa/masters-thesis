\chapter{Background}
\label{chapter:background}

From a medical standpoint, to perform their studies, biomedical researches need to
contact data owners to have access to relevant data that can help improve their
analysis and/or findings that can be applied to real cases.

% estudam doen√ßas
% percisam de fazer analyses
% isto percisa de dados

With this procedure emerges several problems for the researcher such as he has to find
institutions willing to share data and the process of contacting the data providers can
be cumbersome.
To aid in this whole process, several data hubs have been developed with the purpose of
making the process of data discovery easier.
One important aspect of such data hubs is that they present to the researcher meta
data, which is aggregations or summaries of the original data.
Metadata has the advantage that one doesn't have to deal with the anonymization process
of medical records, since only summaries of the initial data are retrieved
~\cite{egenvar, montra}.
With this dependency on the original data, emerges an important problem of data hubs
which is, metadata can easily be outdated after a small time window.
This could not raise a big problem, if the records were updated regularly, however this
rarely happens, mainly because either the update process is difficult or because
metadata has to be manually extracted and uploaded to the data hub.
A problem that still might arise from such platforms, is those different datasets very
often have different representation for the same concept or the data is organized in a
different layout.
The research is then hampered since either different approaches have to be taken to
analyze each dataset.

The \gls{ehden} project has affiliations with several institutions, data sources and
data custodians across the \gls{eu}, which the main goal is to, within a federated
network, harmonize their data to the \gls{omop} \gls{cdm}~\cite{ehden-datapartners}.
With a \gls{cdm}, the problem of having different representations for the same data
across distinct data sources is solved.
Researchers can now develop a single analysis method and then apply it to all gathered
datasets and these methods can be optimized for this specific data model, which allows
large-scale analytics.
Furthermore, also improves collaborative research~\cite{ohdsi-site}.
Still, within the scope of the \gls{ehden} project, the project has a database catalog,
built with the Montra framework~\cite{montra}, where data owners fill metadata about
their data source manually, which brings the outdated problem already mentioned before.
Additionally, whenever new metadata fields are introduced, the data owners of all data
sources have to go manually update their metadata form.

To build a valuable data hub is then important to take into account how to:
\begin{itemize}
    \item extract metadata from a data source
    \item upload and update the metadata on the data hub
    \item automatize the two processes mentioned before
    \item receive and display the metadata on the data hub in a way that facilitates
        readability.
\end{itemize}

\section{Metadata visualization tools}
It will then be explored existing visualization platforms that enhance data discovery
by presenting summaries or metadata of records (data sources, datasets).

In some cases data can't be publicly available because it contains sensitive data or
simply the data owner might not want to share some portions of the data, for that the
tools analyzed should have privacy protection mechanisms, allowing to customize the
access and manipulation of data stored.

Furthermore, considering we want to improve and assist data discovery and reuse it is
important to have good data management to simplify such processes.
However, humans fail to achieve the necessary processing levels with present-day
scientific data.
It is then important that data is provided in such a way that machines can fetch,
understand, analyze and act on data.
For that the \gls{fair} Guiding Principles were established which contain a series of
considerations for data publishing to supports both human and machine operations such
as deposition, exploration, sharing and reuse~\cite{fair}.

Finally, it is preferential for such a tool to be open source since the available
solution might need some changes to solve our specific problem, and also it makes it
possible to receive contributions from the community.

\subsection{Search Method}

Regarding this subject, there was already done a systematic review of several tools
that fit within the current search pool.
Its objective was to ``identify projects and software solutions that promote patient
electronic health data discovery, as enablers for data reuse and advancement of
biomedical and translational research''~\cite{systematic_review}.
From the final 20 systems, they captured their interoperability, what type of data they
were providing and their after effect related to scientific results and improvements to
better healthcare.
To perform their search they only used PubMed
\footnote{https://pubmed.ncbi.nlm.nih.gov/} considering it indexes a substantially
amount of health-care related work and provides a public \gls{api} which allows
automation of the retrieval process.
The programmatic retrieval was done using the Biopython
framework\footnote{https://biopython.org/} where all search queries were limited to the
time windows between January 2014 to September 2018.

A softer version of the previous systematic review was done now within November 2018
and January 2021.
Also, instead of doing a query to PubMed and then find related publications, the
process taken here was to skip the first step and find related publications of the
final 16 selected on the systematic review and then try to find some software solutions
of interest.

\subsection{Findings}

From the systematic review mentioned before, only software solutions were considered
and projects were excluded.

\begin{tabular}{ | c | c | c | c | c | }
\hline 
Tool Name & Open Source & Data protection  & FAIR\\
\hline
eGenVar \cite{egenvar} & {\color{green} \cmark} \footnotemark & {\color{green} \cmark} (Users + Permissions)& {\color{green} \cmark} \\
\hline
MONTRA \cite{montra} & {\color{green} \cmark} \footnotemark & {\color{green} \cmark} (Role based) & {\color{green} \cmark} \\
\hline
REDCap \cite{redcap} & {\color{red} \xmark} & {\color{green} \cmark} (Role based) & {\color{green} \cmark} \\
\hline
Data Sphere \cite{datasphere} & {\color{red} \xmark} & {\color{green} \cmark} (Authorized Users Only) & {\color{red} \xmark} \\
\hline
MOLGENIS \cite{molgenis} & {\color{green} \cmark} \footnotemark & {\color{green} \cmark} (Role based) & {\color{red} \xmark} \\
\hline
GAAIN\cite{gaain} & -- & -- & -- \\
\hline
Cafe Variome \cite{cafevariome} & {\color{red} \xmark} & -- & -- \\
\hline
Harvest \cite{harvest} & {\color{green} \cmark} & -- & -- \\
\hline
PopMedNet \cite{popmednet} & -- & -- & -- \\
\hline
Cataloguing toolkit by Maelstrom \cite{maelstrom} & {\color{green} \cmark} & -- & -- \\
\hline
DataMed \cite{datamed} & {\color{green} \cmark} & -- & -- \\
\hline
YummyData \cite{yummydata} & {\color{green} \cmark} & -- & {\color{green} \cmark} \\
\hline
BioSharing \cite{biosharing} & -- & -- & -- \\
\hline
Open PHACTS \cite{phacts} & -- & -- & -- \\
\hline
\end{tabular}

\footnotetext{https://github.com/Sabryr/EGDMS} % egenvar
\footnotetext{https://github.com/bioinformatics-ua/montra}
\footnotetext{https://github.com/molgenis/molgenis}

\textbf{eGenVar \cite{egenvar}:}

A software suite called the eGenVar data-management system (EGDMS), allows users to
report, track, and share metadata on data content, origin and history of files, without
compromising privacy or security, since could be used to search data while the original
files remain in a secure location.
Users need to have an account to access the system and once created can immediately
start using the system for search operations.
However, a personal profile needs to be created before adding, deleting or updating
content.
It is designed to connect current Laboratory Information Management Systems (LIMS) and
workflow processing systems and to keep origin information for data being processed
through distinct systems at different locations.
Central to the system is a tagging process that allows users to tag data with new or
pre-existing information, such as ontology terms or controlled vocabularies, at their
convenience.
The system includes a server, a command-line client, other clients that can be
developed in several programming languages and a web portal interface.


\textbf{MONTRA \cite{montra}:}
A base architecture for designing data integration platforms, with emphasis on
biomedical data.
It has a flexible architecture for centralizing and sharing such data coming from
multiple, heterogeneous sources.
The data sources that are cataloged within the system contain the full data, while the
views available through MONTRA provide a skeleton of these underlying sources.
The use of a dynamic data skeleton for data characterization and integration represents
a layer of abstraction that does not depend on data models or physical data supports.
The skeleton definition is a straightforward operation that can be done by any data
custodian and can be saved as a spreadsheet file and submitted through the web
interface.
Furthermore, the user interface allows viewing, searching, modifying and deleting
information through simple forms.
Also, a RESTful API is available which provides a set of programmatic endpoints that
can be consulted by third-party applications.
The main idea behind the Web API is that other applications can send data to MONTRA
containing extra metadata of the registry.
Access is controlled via a Role-Based Access Control (RBAC) system to guarantee that
proper constraints are imposed.
Different data sources following the same skeleton template will have a common
representation within the platform.
By using a common structure as a metadata skeleton, distinct data sources converge to a
homogeneous representation of their metadata.

This framework is in used to deploy the EMIF Catalogue, a platform that aims to be a
marketplace where data custodians can publish and share information about their
clinical databases, while biomedical researchers can search for databases that fulfill
their particular study requirements.
Currently, the EMIF Catalogue supports several distinct projects, combining, for
instance, data available in pan-European EHR and Alzheimer cohorts.

\textbf{\gls{redcap} \cite{redcap}:}
Recognizing the need of those participating in research to be able to securely collect
and share data, a team at Vanderbilt University developed \gls{redcap}, a data and
metadata gathering tool.
\gls{redcap} data capture tools can either be structured to function as a series of
forms that investigators fill out as they advance through a project or as a survey
designed to be completed by subjects.
Building these instruments with the Online Designer tool is similar to the experience
of building online surveys through web survey tools.
With \gls{redcap}'s collaboration functionality, investigators after adding team
members to a project can assign abilities and access to each, based on their roles and
data needs.
One can choose to create custom roles for groups of members or assign permissions
individually.  \gls{redcap} includes several features to help assure data quality.
The Data Quality reports not only identify missing values and outliers, validation
errors, and incorrect values for calculated fields but also allow users to create their
own custom rules to assess data correctness.
Collected data can be observed within \gls{redcap}, which provides views with basic
statistical measures.
The software supports data export to Excel, SPSS, SAS, R, and Stata.
Users may import previously collected data using the Data Import tool.
Finally, \gls{redcap} offers an API to support remote entry and retrieval of data.
There are also many features that enable support for various types of clinical and
basic science research.

In \cite{vanderbilt} the Vanderbilt research data warehouse framework is explained,
which consists of identified and de-identified clinical data repositories and tools
built on top of the data layer to assist researchers across the enterprise, being one
of them \gls{redcap}.
Providing resources dedicated to research initiatives benefits not only the research
community but also clinicians, patients and institutional leadership.
Finally in \cite{braincode}, the Ontario Brain Institute‚Äôs ''Brain-CODE`` is
presented, which is a neuroinformatics platform designed to support the collection,
storage, sharing and analysis of different data types across several brain disorders,
as a means to understand common underlying causes of brain dysfunction and develop new
approaches to treatment.
In here \gls{redcap} is used to collect demographic and clinical data.

\textbf{Data Sphere \cite{datasphere}}
The Data sphere project provides a platform on which industry and academia can share
raw data from late-phase oncology clinical trials.
Provides of data to this project sign a data sharing agreement were contains some
metadata about the data that is being proposed to upload, which then they have to
follow instructions to upload the given data to the platform.
On approval of the data application, authorized users can access and download all
datasets on the platform.
To get be authorized, the project only requires an application with information about
the background of the individual requesting access and an agreement to the terms of
use.
This level of openness avoids having to apply for a single data set at a time and
allows researchers to pool data from several different sponsors to develop a better
cohort for analysis.
Patient privacy is in the responsibility of the data providers, where they have to
deidentify data according to standards set forth by the Privacy Rule of the U.S. Health
Insurance Portability and Accountability Act of 1996.

As of January 2020, the PDS website had available cancer trial data from 150 trials
including 100,000 subjects \cite{datasphere-site}.

\textbf{Molgenis \cite{molgenis}}
MOLGENIS is a generic, model-driven toolkit for the rapid generation of custom-made,
data-intensive biosoftware applications.
Bioinformaticians can use a domain-specific language to efficiently model the
biological details of their particular biological system, which enables compact
specification of what experiment database is needed.
The level of abstraction is raised, so no lengthy, technical or redundant details on
how each feature should be implemented in general programming languages have to be
given. The domain-specific language was implemented using XML.
Bioinformaticinas can also use MOLGENIS software generation tools to automatically
generate a web application tailored to the experiments of their biologists, building on
reusable components.
The authors found up to 30 times efficiency improvement compared to hand-writing
software, while providing a richness of features practically unfeasible to produce by
hand but not yet provided by related projects.

The \gls{bbmri-eric} project~\cite{bbmrieric} provides fair access to quality-controlled human
biological samples and associated biomedical and biomolecular data, enabling the
investigation of basic mechanisms underlying diseases, indispensable for the
development of new biomarkers and drugs.
Here Molgenis is used to develop their Directory 1.0 which provides an overview of the
BBMRI-ERIC ecosystem with its distributed structure of National Nodes, and even more
importantly to help users identify biobanks of interest to them.
RD-Connect~\cite{rdconnect} is a global infrastructure project initiated that links
genomic data with patient registries, biobanks, and clinical bioinformatics tools to
create a central research resource for \gls{rd}s.
Its composed by the RD-Connect Registry \& Biobank Finder, a tool that helps \gls{rd}
researchers to find \gls{rd} biobanks and registries and provide information on the
availability and accessibility of content in each database.
The finder is also a portal to other RD-Connect tools, providing a link to the
RD-Connect Sample Catalogue, which was developed using MOLGENIS, a large inventory of
RD biological samples available in participating biobanks for RD research. 


\textbf{GAAIN}

\textbf{Cafe Variome \cite{cafevariome}}

\textbf{Harvest \cite{harvest}}

\textbf{PopMedNet \cite{popmednet}}

\textbf{Maelstrom \cite{maelstrom}}

\textbf{DataMed \cite{datamed}}

\textbf{YummyData \cite{yummydata}}

\textbf{BioSharing \cite{biosharing}}

\textbf{Open PHACTS \cite{phacts}}

33334310,Menoci: lightweight extensible web portal enhancing data management for biomedical research projects.

30424756,X-search: an open access interface for cross-cohort exploration of the National Sleep Research Resource.

32047873,ClinEpiDB: an open-access clinical epidemiology database resource encouraging online exploration of complex studies.

30876434,Evaluation of repositories for sharing individual-participant data from clinical studies.

32821064,ACTION-EHR: Patient-Centric Blockchain-Based Electronic Health Record Data Management for Cancer Care.

31862012,The Systematic Review Data Repository (SRDR): descriptive characteristics of publicly available data and opportunities for research.

\section{Fingerprinting Tools}

https://bmcsystbiol.biomedcentral.com/articles/10.1186/s12918-015-0174-y

\cite{maelstrom}

profilling

OMOP CDM

OHDSI TOOLS 

ACHILLES

https://github.com/EHDEN/CatalogueExport

31853911,One Step Away from Technology but One Step Towards Domain Experts-MDRBridge: A Template-Based ISO 11179-Compliant Metadata Processing Pipeline.

32620019,From Raw Data to FAIR Data: The FAIRification Workflow for Health Research.

33267792,LabPipe: an extensible bioinformatics toolkit to manage experimental data and metadata.

30395166,ukbREST: efficient and streamlined data access for reproducible research in large biobanks.

31675914,Annot: a Django-based sample, reagent, and experiment metadata tracking system.

interesting - 30382537,Automated Metadata Suggestion During Repository Submission.

33451426,MARMoSET - Extracting Publication-ready Mass Spectrometry Metadata from RAW Files.

https://github.com/nextgenhealthcare/connect

https://ckan.org/

\section{Network of Fingerprinting agents}
\cite{egenvar}
add file and metada thourgh client

\cite{datasphere}
\cite{ehr4cr}
\cite{popmed}
\cite{gaain}

\cite{bbmieric} Since the existing biobanks have a strong national character and background, BBMRI-ERIC has chosen for itself a distributed hub and-spoke structure. This structure provides great flexibility so that new Member States and Observers can be connected at any time, and so that it is easy to respond to the emerging needs of biomedical research. It aims to facilitate fair access to quality-defined human disease-relevant biological resources including associated data in an efficient as well as ethically and legally compliant manner to reduce the fragmentation of the biomedical research landscape through harmonization of procedures and implementation of common standards to support high-level collaboration, especially through its Common Service IT and Common Service ELSI, which provide a new service model for Pan-European collaboration

31245605,Cross-Network Directory Service: Infrastructure to enable collaborations across distributed research networks.
